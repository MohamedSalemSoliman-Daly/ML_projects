{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e455c577",
   "metadata": {},
   "source": [
    "# <center> Flipkart website scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f18ad",
   "metadata": {},
   "source": [
    "## Project targets\n",
    "- scrap names and prices of labtops from Flipkart website (first page only)\n",
    "- Create function to extract multible pages of the same website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38780a2c",
   "metadata": {},
   "source": [
    "- Scrape the **Flipkart** website to extract the **Name**, **Price**, and **Rating** of Laptops.\n",
    "<br>\n",
    "- Page link:  https://www.flipkart.com/search?q=laptops&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&as-pos=1&as-type=HISTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f152c3",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee8c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as req"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e323ab8",
   "metadata": {},
   "source": [
    "### Request page url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475ec084",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/search?q=laptops&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&as-pos=1&as-type=HISTORY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ee52ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = req.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c66ab73",
   "metadata": {},
   "source": [
    "## Extracting HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0417b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract html content (unorganised form)\n",
    "html=page.content\n",
    "# Extract html content (organised form)\n",
    "soup = bs(html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b968e",
   "metadata": {},
   "source": [
    "The data is usually nested in tags. So, we inspect the page to see, under which tag the data we want to scrape is nested.\n",
    "- choose element to inspect\n",
    "-  right click on the element and click on “Inspect”\n",
    "-  “Browser Inspector Box”\n",
    "- Search for **Tag** and **class** where the **data / information** we want to extract is nested\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af8669",
   "metadata": {},
   "source": [
    "###  Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ab9e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lenovo IdeaPad Gaming 3 Core i5 11th Gen - (8 GB/512 GB SSD/Windows 10 Home/4 GB Graphics/NVIDIA GeFor...',\n",
       " bs4.element.ResultSet)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_scrap=soup.find_all(\"div\",{\"class\":\"_4rR01T\"})\n",
    "names_scrap[0].text, type(names_scrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e81766",
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=[]\n",
    "for name in range(len(names_scrap)):\n",
    "    Names.append(names_scrap[name].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b3104",
   "metadata": {},
   "source": [
    "### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "252f32ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('₹57,990', 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Price_scrap=soup.find_all(\"div\",{\"class\":\"_30jeq3 _1_WHN1\"})\n",
    "Price_scrap[0].text, len(Price_scrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e825fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price=[]\n",
    "for i in range(len(Price_scrap)):\n",
    "    Price.append(Price_scrap[i].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ada7d",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b7c647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Core i5 11th Gen - (8 ...</td>\n",
       "      <td>₹57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Core i5 10th Gen - (8 ...</td>\n",
       "      <td>₹54,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 15 Core i3 10th Gen - (8 GB/1 TB...</td>\n",
       "      <td>₹29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook 15 (2022) Core i5 11th Gen - (8 ...</td>\n",
       "      <td>₹48,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad 3 Core i3 10th Gen - (8 GB/256 ...</td>\n",
       "      <td>₹35,490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Names    Price\n",
       "0  Lenovo IdeaPad Gaming 3 Core i5 11th Gen - (8 ...  ₹57,990\n",
       "1  Lenovo IdeaPad Gaming 3 Core i5 10th Gen - (8 ...  ₹54,990\n",
       "2  ASUS VivoBook 15 Core i3 10th Gen - (8 GB/1 TB...  ₹29,990\n",
       "3  ASUS VivoBook 15 (2022) Core i5 11th Gen - (8 ...  ₹48,990\n",
       "4  Lenovo IdeaPad 3 Core i3 10th Gen - (8 GB/256 ...  ₹35,490"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "df['Names']=Names\n",
    "df['Price']=Price\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928de30c",
   "metadata": {},
   "source": [
    "## <center> Scraping Multible pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a290bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tot_url(page_limit):\n",
    "    soup_list=[]\n",
    "    for i in range(1,page_limit+1):\n",
    "        url = f\"https://www.flipkart.com/search?q=laptops&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&as-pos=1&as-type=HISTORY&page={i}\"\n",
    "        page = req.get(url)\n",
    "        html=page.content\n",
    "        soup = bs(html, \"lxml\")\n",
    "        soup_list.append(soup)\n",
    "    print(len(soup_list))\n",
    "    return soup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d16a8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(soup_list,tag_name,class_name):\n",
    "    scrap=[]\n",
    "    for soup in soup_list:\n",
    "        R_scrap=soup.find_all(tag_name,{\"class\":class_name})\n",
    "        for i in range(len(R_scrap)):\n",
    "            scrap.append(R_scrap[i].text)\n",
    "    return scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41126451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('acer Extensa 15 Core i3 11th Gen - (4 GB/256 GB SSD/Windows 11 Home) EX215-54 Thin and Light Laptop',\n",
       " '₹31,990')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_list=tot_url(10)\n",
    "Name_scrap=scrap(soup_list,\"div\",\"_4rR01T\")\n",
    "Price_scrap=scrap(soup_list,\"div\",\"_30jeq3 _1_WHN1\")\n",
    "Name_scrap[0],Price_scrap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50a1a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=[]\n",
    "Price=[]\n",
    "for i in range(len(Name_scrap)):\n",
    "    Names.append(Name_scrap[i])\n",
    "    Price.append(Price_scrap[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cb2d2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acer Extensa 15 Core i3 11th Gen - (4 GB/256 G...</td>\n",
       "      <td>₹31,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acer Aspire 3 Ryzen 3 Dual Core 3250U - (8 GB/...</td>\n",
       "      <td>₹35,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 15 Core i3 10th Gen - (8 GB/1 TB...</td>\n",
       "      <td>₹29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook 15 (2022) Core i5 11th Gen - (8 ...</td>\n",
       "      <td>₹48,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad 3 Core i3 10th Gen - (8 GB/256 ...</td>\n",
       "      <td>₹35,490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Names    Price\n",
       "0  acer Extensa 15 Core i3 11th Gen - (4 GB/256 G...  ₹31,990\n",
       "1  acer Aspire 3 Ryzen 3 Dual Core 3250U - (8 GB/...  ₹35,990\n",
       "2  ASUS VivoBook 15 Core i3 10th Gen - (8 GB/1 TB...  ₹29,990\n",
       "3  ASUS VivoBook 15 (2022) Core i5 11th Gen - (8 ...  ₹48,990\n",
       "4  Lenovo IdeaPad 3 Core i3 10th Gen - (8 GB/256 ...  ₹35,490"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "df['Names']=Names\n",
    "df['Price']=Price\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715888de",
   "metadata": {},
   "source": [
    "## sources\n",
    "- Tutorial of multible page scrapping\n",
    "https://data36.com/scrape-multiple-web-pages-beautiful-soup-tutorial/\n",
    "- A guide to web scraping in Python using Beautiful Soup\n",
    "https://opensource.com/article/21/9/web-scraping-python-beautiful-soup\n",
    "- tutorial of web scraping\n",
    "https://getpocket.com/read/3581062331"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65639f90",
   "metadata": {},
   "source": [
    "### Summary of important steps\n",
    "    1-Request url of page \n",
    "        -page = req.get(url)\n",
    "    2-getting the html of page (unorganised formate)\n",
    "        -html=page.content\n",
    "    3- getting soup of page (organised html)\n",
    "        -soup = bs(html,\"html.parser\")\n",
    "    4- inspect the page to know which tag and class related to your data\n",
    "    5-Extract your data\n",
    "        -names_scrap=soup.find_all(\"div\",{\"class\":\"_4rR01T\"})\n",
    "        -names_scrap[0].text\n",
    "    6- loop for all elements \n",
    "        -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
